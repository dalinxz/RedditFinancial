# -*- coding: utf-8 -*-
"""extract_akash.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TmzJzpe4OrcyMnx7YIT7ao6k4BtdQNIs
"""

#SubReddit Extracting Code - Akash, Sachin, Surya

!pip install praw

import praw
import time
import requests #idk why we need request? but ok
import requests.auth
import pandas as pd
from google.colab import drive
drive.mount('drive', force_remount=True)

reddit = praw.Reddit(
     client_id="wal33qeX5QhkVQ",
     client_secret="5Jv5XrScw3sTCuHE18j-YOUzeaKBjw",
     user_agent="script:test_app:v0.1 (by u/Comprehensive-Self39)"
 )

"""
def extract_data_to_csv(sub_reddits =[]):
  columns = ['Title', 'Flair', 'Score of Post', 'ID', 'URL', 'TimeStamp', 'Message body', '#Comments', 'SubReddit']
  accepted_tags_WSB = ['None', 'Charts', 'Earnings Thread', 'Gain', 'Loss', 'News'] 
  list_attr = []
  for sub_reddit in sub_reddits:
    print('sub_reddit: ', sub_reddit)
    title = []; flair = []; score = []; id = []; url = []; creation = []; message = []; numComments = []; label=[]; count = 0;
    for submission in reddit.subreddit(sub_reddit).hot(limit=1000):
      if (sub_reddit == 'wallstreetbets'):
        if submission.link_flair_text in accepted_tags_WSB:
          if submission.over_18 == False:
            numComments.append(submission.num_comments)
            flair.append(submission.link_flair_text)
            title.append(submission.title)
            score.append(submission.score)
            id.append(submission.id)
            url.append(submission.url)
            creation.append(submission.created_utc)
            message.append(submission.selftext)
            label.append(sub_reddit)
            count += 1
      else:
        numComments.append(submission.num_comments)
        flair.append(submission.link_flair_text)
        title.append(submission.title)
        score.append(submission.score)
        id.append(submission.id)
        url.append(submission.url)
        creation.append(submission.created_utc)
        message.append(submission.selftext)
        label.append(sub_reddit)
        count += 1
        
    for submission in reddit.subreddit(sub_reddit).top(limit=1000):
      if (sub_reddit == 'wallstreetbets'):
        if submission.link_flair_text in accepted_tags_WSB:
          if submission.over_18 == False:
            numComments.append(submission.num_comments)
            flair.append(submission.link_flair_text)
            title.append(submission.title)
            score.append(submission.score)
            id.append(submission.id)
            url.append(submission.url)
            creation.append(submission.created_utc)
            message.append(submission.selftext)
            label.append(sub_reddit)
            count += 1
      else:
        numComments.append(submission.num_comments)
        flair.append(submission.link_flair_text)
        title.append(submission.title)
        score.append(submission.score)
        id.append(submission.id)
        url.append(submission.url)
        creation.append(submission.created_utc)
        message.append(submission.selftext)
        label.append(sub_reddit)
        count += 1
  extract_array = [title, flair, score, id, url, creation, message, numComments, label]
  extract_db = dict(zip(columns, extract_array))
  df_out = pd.DataFrame(extract_db)
  return df_out
  #df_out.to_csv('drive/Shared with me/WSB Debullshitter/CSV_Files/'+subreddit_csv)
  


#def update_data(data = []):
  #


#can't upload to shared drives which is an L
df_out = extract_data_to_csv(sub_reddits=['financialindependence', 'wallstreetbets', 'options', 'stocks'])
"""

#^Code isn't as useful

df_out.to_csv('/content/drive/My Drive/redditFinances.csv')

#better function, sorts by time(within year) and pulls as many top posts as possible
def extract_data_to_csv(sub_reddits =[]):
  time_UTC = time.time()
  year = 31556926
  last_acc_time = time_UTC - year
  columns = ['Title', 'Flair', 'Score of Post', 'ID', 'URL', 'TimeStamp', 'Message body', '#Comments', 'SubReddit']
  accepted_tags_WSB = ['None', 'Charts', 'Earnings Thread', 'Gain', 'Loss', 'News'] 
  list_attr = []
  title = []; flair = []; score = []; id = []; url = []; creation = []; message = []; numComments = []; label=[]; count = 0;
  for sub_reddit in sub_reddits:
    print('sub_reddit: ', sub_reddit)
    for submission in reddit.subreddit(sub_reddit).top(limit=None):
      if (sub_reddit == 'wallstreetbets'):
        if submission.link_flair_text in accepted_tags_WSB:
          if submission.over_18 == False:
            if submission.created_utc > last_acc_time:
              numComments.append(submission.num_comments)
              flair.append(submission.link_flair_text)
              title.append(submission.title)
              score.append(submission.score)
              id.append(submission.id)
              url.append(submission.url)
              creation.append(submission.created_utc)
              message.append(submission.selftext)
              label.append(sub_reddit)
              count += 1
      else:
        if submission.created_utc > last_acc_time:
          numComments.append(submission.num_comments)
          flair.append(submission.link_flair_text)
          title.append(submission.title)
          score.append(submission.score)
          id.append(submission.id)
          url.append(submission.url)
          creation.append(submission.created_utc)
          message.append(submission.selftext)
          label.append(sub_reddit)
          count += 1
  extract_array = [title, flair, score, id, url, creation, message, numComments, label]
  extract_db = dict(zip(columns, extract_array))
  df_out = pd.DataFrame(extract_db)
  return df_out

df_out = extract_data_to_csv(sub_reddits=['financialindependence'])
df_out1 = extract_data_to_csv(sub_reddits=['wallstreetbets'])
df_out2 = extract_data_to_csv(sub_reddits=['options'])
df_out3 = extract_data_to_csv(sub_reddits=['stocks'])

df_out.to_csv('/content/drive/My Drive/financialindependence.csv')
df_out1.to_csv('/content/drive/My Drive/wallstreetbets.csv')
df_out2.to_csv('/content/drive/My Drive/options.csv')
df_out3.to_csv('/content/drive/My Drive/stocks.csv')

subred = reddit.subreddit('wallstreetbets')
print(dir(subred.top))